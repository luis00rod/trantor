{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bddd5e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\pyspark\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "import spacy,en_core_web_sm\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import Matcher\n",
    "import textacy\n",
    "import string\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import numpy as np\n",
    "import nltk\n",
    "import locationtagger\n",
    "from difflib import SequenceMatcher\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0fc50e",
   "metadata": {
    "code_folding": [
     0,
     8,
     24,
     35,
     38,
     49,
     77
    ]
   },
   "outputs": [],
   "source": [
    "class MlSkillsOne:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        self.all_records_raw_df = self.read_data_individual_topics()\n",
    "        self.all_records_cleaned_df = self.data_cleaner()\n",
    "        self.target_phrase = \"Jeu de Paume is an excellent art gallery in Paris\"        \n",
    "\n",
    "    def read_data_individual_topics(self):\n",
    "\n",
    "        path = 'individualTopics_27-01-22/'\n",
    "        all_records = []\n",
    "\n",
    "        for fname in glob.glob(path + '*.pickle'):\n",
    "            obj = pd.read_pickle(fname)\n",
    "            record = [obj['id'],obj['name'],obj['audience_size'],\n",
    "                      obj['country'],obj['topic']]\n",
    "            all_records = all_records + [record]\n",
    "        \n",
    "        all_records_df = pd.DataFrame.from_records(all_records)\n",
    "        all_records_df.columns = ['id','name','audience_size','country','topic']\n",
    "        \n",
    "        return all_records_df\n",
    "    \n",
    "    def number_of_verb(self, string):\n",
    "        verbs = []\n",
    "        pattern = [{'POS': 'VERB', 'OP': '?'},\\\n",
    "               {'POS': 'VERB', 'OP': '+'}]\n",
    "        doc = textacy.make_spacy_doc(string, lang='en_core_web_sm')\n",
    "        lists = textacy.extract.matches.token_matches(doc, [pattern])\n",
    "        for list in lists:\n",
    "            verbs.append(list.text)\n",
    "            \n",
    "        return len(verbs)\n",
    "    \n",
    "    def number_letters(self, string):\n",
    "        return len([i for i in string if i.isalpha()])\n",
    "    \n",
    "    def location(self, string):\n",
    "        place_entity = locationtagger.find_locations(text = string)\n",
    "        countries = place_entity.countries\n",
    "        regions = place_entity.regions\n",
    "        cities = place_entity.cities\n",
    "        X = countries + regions + cities\n",
    "        return X\n",
    "\n",
    "    def similarity(self, row):\n",
    "        return SequenceMatcher(None, row, \"Jeu de Paume is an excellent art gallery in Paris\").ratio()\n",
    "    \n",
    "    def data_cleaner(self):\n",
    "\n",
    "        self.all_records_raw_df[\"name_cleaned\"] = self.all_records_raw_df.name\\\n",
    "            .apply(lambda row: row.translate(str.maketrans('', '', string.punctuation)))\n",
    "        \"\"\"\n",
    "        self.all_records_raw_df[\"number_of_verb\"] = self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: self.number_of_verb(row))\n",
    "        \n",
    "        self.all_records_raw_df[\"number_words\"] = self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: len(row.split()))\n",
    "            \n",
    "        self.all_records_raw_df[\"number_letters\"] = self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: self.number_letters(row))\n",
    "        \n",
    "        self.all_records_raw_df[\"number_letters_words_verbs\"] = self.all_records_raw_df.number_letters.\\\n",
    "            apply(lambda row: [row]) + self.all_records_raw_df.number_words.apply(lambda row: [row]) + \\\n",
    "            self.all_records_raw_df.number_of_verb.apply(lambda row: [row])\n",
    "         \n",
    "        self.all_records_raw_df[\"name_entity\"] =  self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: self.location(row))  \n",
    "        \"\"\" \n",
    "        self.all_records_raw_df[\"similarity\"] =  self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: self.similarity(row))\n",
    "        \n",
    "        self.all_records_raw_df[\"target_phrase\"] = \"Jeu de Paume is an excellent art gallery in Paris\"\n",
    "        \n",
    "        return self.all_records_raw_df\n",
    "        \n",
    "    def word_cloud(self):\n",
    "        string = self.all_records_raw_df.name_cleaned\n",
    "        comment_words = ''\n",
    "        stopwords = set(STOPWORDS)\n",
    "        for val in string:\n",
    "\n",
    "            # typecaste each val to string\n",
    "            val = str(val)\n",
    "\n",
    "            # split the value\n",
    "            tokens = val.split()\n",
    "\n",
    "            # Converts each token into lowercase\n",
    "            for i in range(len(tokens)):\n",
    "                tokens[i] = tokens[i].lower()\n",
    "\n",
    "            comment_words += \" \".join(tokens)+\" \"\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800,\n",
    "                    background_color ='white',\n",
    "                    stopwords = stopwords,\n",
    "                    min_font_size = 10).generate(comment_words)\n",
    "\n",
    "        # plot the WordCloud image                      \n",
    "        plt.figure(figsize = (8, 8), facecolor = None)\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad = 0)\n",
    "\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae699129",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MlSkillsTwo:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        self.instance_data = self.read_instances()\n",
    "        self.variables = pd.DataFrame(self.read_variables(),\\\n",
    "                                      columns= ('var1','var2','var3','var4','var5'))\n",
    "        \n",
    "    def read_instances(self):\n",
    "        \n",
    "        with open(\"data.pickle\", \"rb\") as file:\n",
    "            instances = pickle.load(file)\n",
    "            \n",
    "        return instances    \n",
    "    \n",
    "    def read_variables(self):\n",
    "    \n",
    "        with open(\"variables.pickle\", \"rb\") as file:\n",
    "            variables = pickle.load(file)\n",
    "            \n",
    "        return variables\n",
    "    \n",
    "    def transform_instance(self):\n",
    "            elements = []\n",
    "            instances_list = []\n",
    "            total_df = pd.DataFrame()\n",
    "            for instance in range(0, len(self.instance_data[:])):\n",
    "\n",
    "                elements = []\n",
    "\n",
    "                for ele in range(len(self.instance_data[instance][0])):\n",
    "                    elements.append(\"ele\" + str(ele))\n",
    "\n",
    "                #print(self.instance_data[instance][0])\n",
    "                #print(elements)\n",
    "                total_df = pd.DataFrame(self.instance_data[instance], columns=elements)\n",
    "                instances_list.append(total_df)\n",
    "                #total_df[\"var1\"] = self.variables[instance]\n",
    "\n",
    "            return instances_list\n",
    "    \n",
    "    \n",
    "    def concatenation(self):\n",
    "        instance = []\n",
    "        for dataframe in range(0,len(self.transform_instance())):\n",
    "                instance.append(pd.concat([self.transform_instance()[dataframe]['ele0'],\\\n",
    "                                           self.variables], axis=1).values.tolist())\n",
    "        return instance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5bcdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_trantor = MlSkillsTwo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66b8d08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Born', 90.0, 10.0, 45.0, 25.0, 15.0]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_trantor.concatenation()[6][32:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f299eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23b80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fb8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424139e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c578b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487e6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category = []\n",
    "# for ele in range(0, to_trantor.transform_instance()[dataframe].shape[1]):\n",
    "#     for dataframe in range(0,len(to_trantor.transform_instance())):\n",
    "#         category.append(pd.concat([to_trantor.transform_instance()[dataframe]['ele'\\\n",
    "#                 + str(ele)], to_trantor.variables], axis=1).values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb28cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
