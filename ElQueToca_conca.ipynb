{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bddd5e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "import spacy,en_core_web_sm\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import Matcher\n",
    "import textacy\n",
    "import string\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import numpy as np\n",
    "import nltk\n",
    "import locationtagger\n",
    "from difflib import SequenceMatcher\n",
    "import pickle\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0fc50e",
   "metadata": {
    "code_folding": [
     0,
     8,
     24,
     35,
     38,
     49,
     77
    ]
   },
   "outputs": [],
   "source": [
    "class MlSkillsOne:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        self.all_records_raw_df = self.read_data_individual_topics()\n",
    "        self.all_records_cleaned_df = self.data_cleaner()\n",
    "        self.target_phrase = \"Jeu de Paume is an excellent art gallery in Paris\"        \n",
    "\n",
    "    def read_data_individual_topics(self):\n",
    "\n",
    "        path = 'individualTopics_27-01-22/'\n",
    "        all_records = []\n",
    "\n",
    "        for fname in glob.glob(path + '*.pickle'):\n",
    "            obj = pd.read_pickle(fname)\n",
    "            record = [obj['id'],obj['name'],obj['audience_size'],\n",
    "                      obj['country'],obj['topic']]\n",
    "            all_records = all_records + [record]\n",
    "        \n",
    "        all_records_df = pd.DataFrame.from_records(all_records)\n",
    "        all_records_df.columns = ['id','name','audience_size','country','topic']\n",
    "        \n",
    "        return all_records_df\n",
    "    \n",
    "    def number_of_verb(self, string):\n",
    "        verbs = []\n",
    "        pattern = [{'POS': 'VERB', 'OP': '?'},\\\n",
    "               {'POS': 'VERB', 'OP': '+'}]\n",
    "        doc = textacy.make_spacy_doc(string, lang='en_core_web_sm')\n",
    "        lists = textacy.extract.matches.token_matches(doc, [pattern])\n",
    "        for list in lists:\n",
    "            verbs.append(list.text)\n",
    "            \n",
    "        return len(verbs)\n",
    "    \n",
    "    def number_letters(self, string):\n",
    "        return len([i for i in string if i.isalpha()])\n",
    "    \n",
    "    def location(self, string):\n",
    "        place_entity = locationtagger.find_locations(text = string)\n",
    "        countries = place_entity.countries\n",
    "        regions = place_entity.regions\n",
    "        cities = place_entity.cities\n",
    "        X = countries + regions + cities\n",
    "        return X\n",
    "\n",
    "    def similarity(self, row):\n",
    "        return SequenceMatcher(None, row, \"Jeu de Paume is an excellent art gallery in Paris\").ratio()\n",
    "    \n",
    "    def data_cleaner(self):\n",
    "\n",
    "        self.all_records_raw_df[\"name_cleaned\"] = self.all_records_raw_df.name\\\n",
    "            .apply(lambda row: row.translate(str.maketrans('', '', string.punctuation)))\n",
    "        \"\"\"\n",
    "        self.all_records_raw_df[\"number_of_verb\"] = self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: self.number_of_verb(row))\n",
    "        \n",
    "        self.all_records_raw_df[\"number_words\"] = self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: len(row.split()))\n",
    "            \n",
    "        self.all_records_raw_df[\"number_letters\"] = self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: self.number_letters(row))\n",
    "        \n",
    "        self.all_records_raw_df[\"number_letters_words_verbs\"] = self.all_records_raw_df.number_letters.\\\n",
    "            apply(lambda row: [row]) + self.all_records_raw_df.number_words.apply(lambda row: [row]) + \\\n",
    "            self.all_records_raw_df.number_of_verb.apply(lambda row: [row])\n",
    "         \n",
    "        self.all_records_raw_df[\"name_entity\"] =  self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: self.location(row))  \n",
    "        \"\"\" \n",
    "        self.all_records_raw_df[\"similarity\"] =  self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: self.similarity(row))\n",
    "        \n",
    "        self.all_records_raw_df[\"target_phrase\"] = \"Jeu de Paume is an excellent art gallery in Paris\"\n",
    "        \n",
    "        return self.all_records_raw_df\n",
    "        \n",
    "    def word_cloud(self):\n",
    "        string = self.all_records_raw_df.name_cleaned\n",
    "        comment_words = ''\n",
    "        stopwords = set(STOPWORDS)\n",
    "        for val in string:\n",
    "\n",
    "            # typecaste each val to string\n",
    "            val = str(val)\n",
    "\n",
    "            # split the value\n",
    "            tokens = val.split()\n",
    "\n",
    "            # Converts each token into lowercase\n",
    "            for i in range(len(tokens)):\n",
    "                tokens[i] = tokens[i].lower()\n",
    "\n",
    "            comment_words += \" \".join(tokens)+\" \"\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800,\n",
    "                    background_color ='white',\n",
    "                    stopwords = stopwords,\n",
    "                    min_font_size = 10).generate(comment_words)\n",
    "\n",
    "        # plot the WordCloud image                      \n",
    "        plt.figure(figsize = (8, 8), facecolor = None)\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad = 0)\n",
    "\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae699129",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MlSkillsTwo:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.instance_data = self.read_instances()\n",
    "        self.variables_df = pd.DataFrame(self.read_variables(),\\\n",
    "                                      columns= ('var1','var2','var3','var4','var5'))\n",
    "        self.instances_list = self.transform_instance()\n",
    "        self.flat_instace = self.concatenation()\n",
    "        \n",
    "    def read_instances(self):\n",
    "        \n",
    "        with open(\"data.pickle\", \"rb\") as file:\n",
    "            instances = pickle.load(file)\n",
    "            \n",
    "        return instances    \n",
    "    \n",
    "    def read_variables(self):\n",
    "    \n",
    "        with open(\"variables.pickle\", \"rb\") as file:\n",
    "            variables = pickle.load(file)\n",
    "            \n",
    "        return variables\n",
    "    \n",
    "    def transform_instance(self):\n",
    "            elements = []\n",
    "            instances_list = []\n",
    "            total_df = pd.DataFrame()\n",
    "            for instance in range(0, len(self.instance_data[:])):\n",
    "\n",
    "                elements = []\n",
    "\n",
    "                for ele in range(len(self.instance_data[instance][0])):\n",
    "                    elements.append(\"ele\" + str(ele))\n",
    "\n",
    "                #print(self.instance_data[instance][0])\n",
    "                #print(elements)\n",
    "                total_df = pd.DataFrame(self.instance_data[instance], columns=elements)\n",
    "                instances_list.append(total_df)\n",
    "                #total_df[\"var1\"] = self.variables[instance]\n",
    "\n",
    "            return instances_list\n",
    "    \n",
    "    \n",
    "    def concatenation(self):\n",
    "        instance = []\n",
    "        for instances_df in range(0, len(self.instances_list)):\n",
    "            for column in self.instances_list[instances_df].columns:\n",
    "                instance.append(pd.concat([self.transform_instance()[instances_df]\\\n",
    "                                [column],self.variables_df], axis=1).\\\n",
    "                                rename(columns = {column:'ele', 'var1':'var1',\\\n",
    "                                'var2':'var2', 'var3':'var3', 'var4':'var4', 'var5':'var5'}))\n",
    "                \n",
    "        instance = pd.concat(instance)\n",
    "        return  instance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5bcdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_trantor = MlSkillsTwo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f1c749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ele</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>65.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nan</td>\n",
       "      <td>85.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mercadillo</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>nan</td>\n",
       "      <td>98.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>nan</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>nan</td>\n",
       "      <td>80.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>nan</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>nan</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128256 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ele  var1  var2  var3  var4  var5\n",
       "0             nan  30.0  55.0  97.0  85.0  50.0\n",
       "1             nan   2.0  60.0  90.0  85.0  95.0\n",
       "2             nan  65.0  96.0  90.0  65.0  90.0\n",
       "3             nan  85.0  45.0   5.0  30.0  10.0\n",
       "4     Mercadillo   90.0  30.0  65.0  20.0   5.0\n",
       "...           ...   ...   ...   ...   ...   ...\n",
       "997           nan  98.0  25.0  10.0  10.0   2.0\n",
       "998           nan  99.0   4.0  45.0   5.0   1.0\n",
       "999           nan  80.0  20.0  50.0  15.0  15.0\n",
       "1000          nan  99.0  10.0  15.0   5.0   1.0\n",
       "1001          nan  40.0  50.0  85.0  65.0   5.0\n",
       "\n",
       "[128256 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_trantor.flat_instace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c2af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = to_trantor.flat_instace.replace('nan', np.nan).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d1bad",
   "metadata": {},
   "source": [
    "## Breve investigacion de WE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dea6946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b09804d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['La ruleta de la suerte']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['ele'][8][18:19].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95361049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary\n",
    "\n",
    "docs  = df_clean['ele'][8][18:19].tolist()\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "txts = [[word for word in document.lower().split() if word not in stoplist]for document in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00f5c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "\n",
    "for text in txts:\n",
    "\n",
    "     for token in text:\n",
    "\n",
    "        frequency[token] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23270c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'la': 0}\n",
      "\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "txts = [[token for token in text if frequency[token] > 1]for text in txts]\n",
    "gensim_dictionary = corpora.Dictionary(txts)\n",
    "print(gensim_dictionary.token2id)\n",
    "doc_new = \"corpus consists document\"\n",
    "vec = gensim_dictionary.doc2bow(doc_new.lower().split())\n",
    "print(\"\\n\",vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8194e8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 2)]]\n"
     ]
    }
   ],
   "source": [
    "gensim_corpus = [gensim_dictionary.doc2bow(text) for text in txts]\n",
    "print(gensim_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a405d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bdffbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a493c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a796e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
