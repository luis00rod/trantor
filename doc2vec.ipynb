{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bddd5e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\pyspark\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "import spacy,en_core_web_sm\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import Matcher\n",
    "import textacy\n",
    "import string\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import numpy as np\n",
    "import nltk\n",
    "import locationtagger\n",
    "from difflib import SequenceMatcher\n",
    "import pickle\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0fc50e",
   "metadata": {
    "code_folding": [
     0,
     8,
     24,
     35,
     38,
     49,
     77
    ]
   },
   "outputs": [],
   "source": [
    "class MlSkillsOne:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        self.all_records_raw_df = self.read_data_individual_topics()\n",
    "        self.all_records_cleaned_df = self.data_cleaner()\n",
    "        self.target_phrase = \"Jeu de Paume is an excellent art gallery in Paris\"        \n",
    "\n",
    "    def read_data_individual_topics(self):\n",
    "\n",
    "        path = 'individualTopics_27-01-22/'\n",
    "        all_records = []\n",
    "\n",
    "        for fname in glob.glob(path + '*.pickle'):\n",
    "            obj = pd.read_pickle(fname)\n",
    "            record = [obj['id'],obj['name'],obj['audience_size'],\n",
    "                      obj['country'],obj['topic']]\n",
    "            all_records = all_records + [record]\n",
    "        \n",
    "        all_records_df = pd.DataFrame.from_records(all_records)\n",
    "        all_records_df.columns = ['id','name','audience_size','country','topic']\n",
    "        \n",
    "        return all_records_df\n",
    "    \n",
    "    def number_of_verb(self, string):\n",
    "        verbs = []\n",
    "        pattern = [{'POS': 'VERB', 'OP': '?'},\\\n",
    "               {'POS': 'VERB', 'OP': '+'}]\n",
    "        doc = textacy.make_spacy_doc(string, lang='en_core_web_sm')\n",
    "        lists = textacy.extract.matches.token_matches(doc, [pattern])\n",
    "        for list in lists:\n",
    "            verbs.append(list.text)\n",
    "            \n",
    "        return len(verbs)\n",
    "    \n",
    "    def number_letters(self, string):\n",
    "        return len([i for i in string if i.isalpha()])\n",
    "    \n",
    "    def location(self, string):\n",
    "        place_entity = locationtagger.find_locations(text = string)\n",
    "        countries = place_entity.countries\n",
    "        regions = place_entity.regions\n",
    "        cities = place_entity.cities\n",
    "        X = countries + regions + cities\n",
    "        return X\n",
    "\n",
    "    def similarity(self, row):\n",
    "        return SequenceMatcher(None, row, \"Jeu de Paume is an excellent art gallery in Paris\").ratio()\n",
    "    \n",
    "    def data_cleaner(self):\n",
    "\n",
    "        self.all_records_raw_df[\"name_cleaned\"] = self.all_records_raw_df.name\\\n",
    "            .apply(lambda row: row.translate(str.maketrans('', '', string.punctuation)))\n",
    "        \"\"\"\n",
    "        self.all_records_raw_df[\"number_of_verb\"] = self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: self.number_of_verb(row))\n",
    "        \n",
    "        self.all_records_raw_df[\"number_words\"] = self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: len(row.split()))\n",
    "            \n",
    "        self.all_records_raw_df[\"number_letters\"] = self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: self.number_letters(row))\n",
    "        \n",
    "        self.all_records_raw_df[\"number_letters_words_verbs\"] = self.all_records_raw_df.number_letters.\\\n",
    "            apply(lambda row: [row]) + self.all_records_raw_df.number_words.apply(lambda row: [row]) + \\\n",
    "            self.all_records_raw_df.number_of_verb.apply(lambda row: [row])\n",
    "         \n",
    "        self.all_records_raw_df[\"name_entity\"] =  self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: self.location(row))  \n",
    "        \"\"\" \n",
    "        self.all_records_raw_df[\"similarity\"] =  self.all_records_raw_df.name_cleaned\\\n",
    "            .apply(lambda row: self.similarity(row))\n",
    "        \n",
    "        self.all_records_raw_df[\"target_phrase\"] = \"Jeu de Paume is an excellent art gallery in Paris\"\n",
    "        \n",
    "        return self.all_records_raw_df\n",
    "        \n",
    "    def word_cloud(self):\n",
    "        string = self.all_records_raw_df.name_cleaned\n",
    "        comment_words = ''\n",
    "        stopwords = set(STOPWORDS)\n",
    "        for val in string:\n",
    "\n",
    "            # typecaste each val to string\n",
    "            val = str(val)\n",
    "\n",
    "            # split the value\n",
    "            tokens = val.split()\n",
    "\n",
    "            # Converts each token into lowercase\n",
    "            for i in range(len(tokens)):\n",
    "                tokens[i] = tokens[i].lower()\n",
    "\n",
    "            comment_words += \" \".join(tokens)+\" \"\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800,\n",
    "                    background_color ='white',\n",
    "                    stopwords = stopwords,\n",
    "                    min_font_size = 10).generate(comment_words)\n",
    "\n",
    "        # plot the WordCloud image                      \n",
    "        plt.figure(figsize = (8, 8), facecolor = None)\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad = 0)\n",
    "\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2720b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.instance_data = self.read_instances()\n",
    "        self.variables_df = self.read_variables()\n",
    "        self.instances_list = self.transform_instance()\n",
    "        self.flat_instance = self.concatenation()\n",
    "        self.corpus = self.flat_instance['element'].map(lambda row: [row]).tolist()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def read_instances() -> list:\n",
    "\n",
    "        with open(\"data.pickle\", \"rb\") as file:\n",
    "            instances = pickle.load(file)\n",
    "\n",
    "        return instances\n",
    "\n",
    "    @staticmethod\n",
    "    def read_variables() -> pd.DataFrame:\n",
    "\n",
    "        with open(\"variables.pickle\", \"rb\") as file:\n",
    "            variables = pickle.load(file)\n",
    "\n",
    "        return pd.DataFrame(variables, columns=('var1', 'var2', 'var3', 'var4', 'var5'))\n",
    "\n",
    "    def transform_instance(self) -> list:\n",
    "        instances_list = []\n",
    "        for instance in range(0, len(self.instance_data[:])):\n",
    "\n",
    "            elements = []\n",
    "\n",
    "            for element in range(len(self.instance_data[instance][0])):\n",
    "                elements.append(\"ele\" + str(element))\n",
    "            total_df = pd.DataFrame(self.instance_data[instance], columns=elements)\n",
    "            instances_list.append(total_df)\n",
    "\n",
    "        return instances_list\n",
    "\n",
    "    def concatenation(self) -> pd.DataFrame:\n",
    "        instance = []\n",
    "        for instances_df in range(0, len(self.instances_list)):\n",
    "            for column in self.instances_list[instances_df].columns:\n",
    "                instance.append(pd.concat([self.transform_instance()[instances_df][column], self.variables_df], axis=1)\n",
    "                                .rename(columns={column: 'element', 'var1': 'var1',\n",
    "                                                 'var2': 'var2', 'var3': 'var3', 'var4': 'var4', 'var5': 'var5'})\n",
    "                                )\n",
    "\n",
    "        instance = pd.concat(instance)\n",
    "        final_instance = instance[instance[\"element\"].str.contains(\"nan\") == False].reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "        return final_instance\n",
    "    \n",
    "#     def tagged_document(self):\n",
    "#         for i, list_of_words in enumerate(self.corpus):\n",
    "#             yield gensim.models.doc2vec.TaggedDocument(self.corpus, [i])\n",
    "     \n",
    "    \n",
    "#     @staticmethod\n",
    "#     def model(corpus):\n",
    "#         data_for_training = list(tagged_document(corpus))\n",
    "#         model = gensim.models.doc2vec.Doc2Vec(vector_size=40, min_count=2, epochs=30)\n",
    "#         model.build_vocab(data_for_training)\n",
    "#         model.train(data_for_training, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "#         print(model.infer_vector(corpus))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5bcdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_trantor = Predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9610512",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_trantor.tagged_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c57020",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_trantor.flat_instance.element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f1c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "((to_trantor.flat_instance.element.apply(lambda x:  len(x.split(' '))) == 1)*1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fdd70a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagged_document(list_of_list_of_words):\n",
    "    for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "        yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b5c409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_training = list(tagged_document(to_trantor.corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85c5b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=40, min_count=2, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d1d7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(data_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7e43c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data_for_training, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "04fd7bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01404235 -0.01076202  0.00224154 -0.0122733  -0.01026767 -0.01080231\n",
      " -0.00098621 -0.01383078  0.01792398  0.00841621  0.00301563 -0.00473961\n",
      " -0.00157053  0.00707933 -0.00764521 -0.01211109  0.00362035 -0.00669797\n",
      "  0.00892563  0.00897956  0.01361649 -0.00078748  0.021214    0.00093932\n",
      " -0.01260184  0.01536596 -0.00510094 -0.01180312 -0.00275389 -0.00702473\n",
      " -0.00436177 -0.00317256 -0.00048458 -0.00087576 -0.00447983 -0.00936608\n",
      " -0.00803289  0.01026737  0.00045672  0.00395049]\n"
     ]
    }
   ],
   "source": [
    "print(model.infer_vector(to_trantor.corpus[89]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f00c1b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = to_trantor.flat_instance.element.apply(lambda x: list(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bbb67311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>element</th>\n",
       "      <th>element</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.013511683, 0.011431031, 0.0070340713, 0.00...</td>\n",
       "      <td>Mercadillo</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.0010123005, 0.011090787, 0.005197478, -0.0...</td>\n",
       "      <td>Primark</td>\n",
       "      <td>99.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.0033996762, -0.008600545, -0.0040092757, 0...</td>\n",
       "      <td>Donde puedo</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.012319372, -0.009114322, 0.0065697506, 0.0...</td>\n",
       "      <td>Mercados ambulantes</td>\n",
       "      <td>75.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0013197904, -0.0015707306, 0.011561666, 0.0...</td>\n",
       "      <td>No compro</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34781</th>\n",
       "      <td>[-0.002646622, -0.011680683, 0.0013522878, 0.0...</td>\n",
       "      <td>Snooker</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34782</th>\n",
       "      <td>[-0.0065622395, 0.00517406, 0.001957188, -0.00...</td>\n",
       "      <td>Zumba</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34783</th>\n",
       "      <td>[0.008511874, -0.0074084178, 0.0012616575, 0.0...</td>\n",
       "      <td>Bouzuki</td>\n",
       "      <td>70.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34784</th>\n",
       "      <td>[0.0031171367, 0.0098148165, 0.010872327, -0.0...</td>\n",
       "      <td>Timple</td>\n",
       "      <td>99.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34785</th>\n",
       "      <td>[-0.010905789, -0.004377457, 0.0102183325, -0....</td>\n",
       "      <td>Laúd y bandurria</td>\n",
       "      <td>85.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34786 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 element              element  \\\n",
       "0      [-0.013511683, 0.011431031, 0.0070340713, 0.00...          Mercadillo    \n",
       "1      [-0.0010123005, 0.011090787, 0.005197478, -0.0...              Primark   \n",
       "2      [-0.0033996762, -0.008600545, -0.0040092757, 0...          Donde puedo   \n",
       "3      [-0.012319372, -0.009114322, 0.0065697506, 0.0...  Mercados ambulantes   \n",
       "4      [0.0013197904, -0.0015707306, 0.011561666, 0.0...            No compro   \n",
       "...                                                  ...                  ...   \n",
       "34781  [-0.002646622, -0.011680683, 0.0013522878, 0.0...             Snooker    \n",
       "34782  [-0.0065622395, 0.00517406, 0.001957188, -0.00...                Zumba   \n",
       "34783  [0.008511874, -0.0074084178, 0.0012616575, 0.0...              Bouzuki   \n",
       "34784  [0.0031171367, 0.0098148165, 0.010872327, -0.0...               Timple   \n",
       "34785  [-0.010905789, -0.004377457, 0.0102183325, -0....     Laúd y bandurria   \n",
       "\n",
       "       var1  var2  var3  var4  var5  \n",
       "0      90.0  30.0  65.0  20.0   5.0  \n",
       "1      99.0  25.0  65.0  80.0  25.0  \n",
       "2      97.0   1.0  20.0  20.0  50.0  \n",
       "3      75.0  65.0  85.0  40.0  90.0  \n",
       "4      99.0  10.0  96.0  40.0   1.0  \n",
       "...     ...   ...   ...   ...   ...  \n",
       "34781  99.0   1.0  35.0  10.0   5.0  \n",
       "34782  15.0  20.0  80.0  15.0  30.0  \n",
       "34783  70.0  15.0  85.0  10.0  20.0  \n",
       "34784  99.0  20.0  70.0   5.0  70.0  \n",
       "34785  85.0  60.0  10.0  60.0   5.0  \n",
       "\n",
       "[34786 rows x 7 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_vectorize = pd.concat([corpus_df.apply(lambda x:(model.infer_vector(x)))\\\n",
    "                              , to_trantor.flat_instance], axis = 1)\n",
    "corpus_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e1d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e604a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64eb85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d3aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6d10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca1036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed79086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720403e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c0cef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde28a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9954c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601f484d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a29da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b16f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d793147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b5603c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "26ac7761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vectorize(corpus):\n",
    "#     data_for_training = list(tagged_document(corpus))\n",
    "#     model = gensim.models.doc2vec.Doc2Vec(vector_size=40, min_count=2, epochs=30)\n",
    "#     model.build_vocab(data_for_training)\n",
    "#     model.train(data_for_training, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "#     print(model.infer_vector(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4e7b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize(corpus[89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25daad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
